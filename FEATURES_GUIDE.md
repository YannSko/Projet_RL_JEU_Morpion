# ðŸŽ® Guide Complet des FonctionnalitÃ©s - Morpion Q-Learning RL

## ðŸ“‹ Table des MatiÃ¨res

1. [Vue d'ensemble](#vue-densemble)
2. [Modes de Jeu](#modes-de-jeu)
3. [SystÃ¨me de Tournoi](#systÃ¨me-de-tournoi)
4. [AutoML - Optimisation Automatique](#automl---optimisation-automatique)
5. [Mode Coach IA](#mode-coach-ia)
6. [Variantes de Jeu](#variantes-de-jeu)
7. [Visualisations](#visualisations)
8. [SystÃ¨me ELO](#systÃ¨me-elo)
9. [Commandes et Utilisation](#commandes-et-utilisation)

---

## ðŸŽ¯ Vue d'ensemble

Ce projet implÃ©mente un systÃ¨me complet de **Reinforcement Learning** pour le jeu de Morpion, avec des fonctionnalitÃ©s avancÃ©es d'analyse, de compÃ©tition et d'optimisation automatique.

### FonctionnalitÃ©s Principales

âœ… **Modes de Jeu Classiques**
- Humain vs Humain
- Humain vs IA (3 niveaux)
- IA vs IA

âœ… **SystÃ¨me de Tournoi**
- Round-Robin (tous contre tous)
- Ã‰limination directe (bracket)
- Classement ELO des modÃ¨les

âœ… **AutoML**
- Grid Search automatique
- Random Search
- Optimisation des hyperparamÃ¨tres

âœ… **Mode Coach IA**
- Hints en temps rÃ©el
- Explication des coups
- Visualisation des Q-values

âœ… **Variantes de Jeu**
- Morpion 4x4
- Morpion 5x5
- Ultimate Tic-Tac-Toe

âœ… **MÃ©triques AvancÃ©es**
- Performance Score
- Efficiency Score
- Robustness Score
- Learning Speed
- Composite Score

---

## ðŸŽ® Modes de Jeu

### 1. Humain vs Humain ðŸ‘¥
Jouez Ã  deux sur le mÃªme ordinateur.

**Utilisation:**
```python
python run.py
# Menu â†’ Humain vs Humain
```

### 2. Humain vs IA ðŸŽ¯
Affrontez l'IA avec 3 niveaux de difficultÃ©:
- **DÃ©butant** (Îµ=0.5): L'IA explore encore, fait des erreurs
- **IntermÃ©diaire** (Îµ=0.2): Bon niveau, quelques erreurs
- **Expert** (Îµ=0.0): Joue toujours le meilleur coup

**Utilisation:**
```python
python run.py
# Menu â†’ Humain vs IA â†’ SÃ©lectionnez le niveau
```

### 3. IA vs IA ðŸ¤–
Regardez deux IAs s'affronter.

---

## ðŸ† SystÃ¨me de Tournoi

### Tournoi Round-Robin

**Description:**
Chaque modÃ¨le joue contre tous les autres. Le classement est basÃ© sur les points:
- Victoire: 3 points
- Nul: 1 point
- DÃ©faite: 0 point

**Utilisation:**

```bash
# Via script
python run_tournament.py

# Via GUI
python run.py
# Menu â†’ Tournoi â†’ SÃ©lectionnez les modÃ¨les â†’ Round-Robin
```

**Exemple de sortie:**
```
ðŸ† CLASSEMENT FINAL
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ðŸ¥‡ model_expert_v5.pkl
   Points: 15 | W-D-L: 5-0-0 | ELO: 1650

ðŸ¥ˆ model_advanced_v3.pkl
   Points: 9 | W-D-L: 3-0-2 | ELO: 1520

ðŸ¥‰ model_baseline.pkl
   Points: 6 | W-D-L: 2-0-3 | ELO: 1480
```

### Tournoi Ã  Ã‰limination

**Description:**
Format bracket Ã  Ã©limination directe. Les gagnants avancent jusqu'Ã  la finale.

**CaractÃ©ristiques:**
- Automatic bye pour nombre impair
- Sudden death en cas d'Ã©galitÃ©
- Affichage du champion

---

## ðŸ¤– AutoML - Optimisation Automatique

### Grid Search

**Description:**
Teste **toutes** les combinaisons d'hyperparamÃ¨tres.

**Configuration par dÃ©faut:**
```python
param_grid = {
    'alpha': [0.1, 0.15, 0.2, 0.25, 0.3],        # 5 valeurs
    'gamma': [0.90, 0.92, 0.95, 0.97, 0.99],     # 5 valeurs
    'epsilon_decay': [0.990, 0.995, 0.997, 0.999] # 4 valeurs
}
# Total: 5 Ã— 5 Ã— 4 = 100 configurations
```

**Utilisation:**
```bash
python run_automl.py

# Choisir Grid Search
# Entrer le nombre d'Ã©pisodes (ex: 10000)
# Entrer le nombre de parties d'Ã©valuation (ex: 100)
```

**Temps estimÃ©:**
- Grid Fast (18 configs): ~15-30 minutes
- Grid Full (100 configs): ~1-2 heures

### Random Search

**Description:**
Ã‰chantillonne alÃ©atoirement dans l'espace des hyperparamÃ¨tres.

**Distributions par dÃ©faut:**
```python
param_distributions = {
    'alpha': (0.05, 0.5),
    'gamma': (0.85, 0.99),
    'epsilon_decay': (0.98, 0.9999),
    'epsilon_min': (0.001, 0.1)
}
```

**Avantages:**
- Plus rapide que Grid Search
- Explore mieux l'espace
- Bon pour trouver des configurations surprenantes

**Utilisation:**
```bash
python run_automl.py
# Choisir Random Search
# Entrer le nombre d'itÃ©rations (ex: 20)
```

### RÃ©sultats

Les rÃ©sultats sont sauvegardÃ©s dans `models/automl_results.csv`:
```csv
config_id,timestamp,config_alpha,config_gamma,win_rate,composite_score,...
1,2026-01-15T12:00:00,0.2,0.95,0.85,87.5,...
2,2026-01-15T12:15:00,0.15,0.99,0.88,89.2,...
```

**Meilleure configuration affichÃ©e:**
```
ðŸ† MEILLEURE CONFIGURATION (Score: 89.2)
  alpha: 0.15
  gamma: 0.99
  epsilon_decay: 0.997
```

---

## ðŸ§‘â€ðŸ« Mode Coach IA

### Description

Le Mode Coach affiche en temps rÃ©el:
1. **Meilleur coup** suggÃ©rÃ©
2. **Q-value** du coup
3. **Niveau de confiance** de l'IA
4. **Explication** stratÃ©gique

### Activation

**MÃ©thode 1: Via le menu**
```python
python run.py
# Menu â†’ Mode Coach (toggle)
```

**MÃ©thode 2: Pendant le jeu**
Appuyez sur la touche `C` pendant une partie

### Interface

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ðŸ§‘â€ðŸ« COACH IA          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Meilleur coup: (1, 1)   â”‚
â”‚ Q-value: 0.875          â”‚
â”‚ Confiance: TRÃˆS CONFIANTâ”‚
â”‚                         â”‚
â”‚ ðŸ›¡ï¸ BLOQUE l'adversaire  â”‚
â”‚ ðŸ“ ContrÃ´le le centre   â”‚
â”‚ âœ¨ Excellent coup       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Types d'explications

- ðŸ† **Coup gagnant**: Ce coup vous fait gagner immÃ©diatement
- ðŸ›¡ï¸ **Bloque l'adversaire**: EmpÃªche l'adversaire de gagner
- ðŸ“ **ContrÃ´le le centre**: Position stratÃ©gique centrale
- ðŸ“ **Position de coin**: Coin stratÃ©gique
- âš”ï¸ **CrÃ©e une menace**: Aligne 2 symboles
- âœ¨ **Excellent coup**: Q-value > 0.8

### Niveaux de confiance

- **TRÃˆS CONFIANT**: DiffÃ©rence de Q-value > 0.5
- **CONFIANT**: DiffÃ©rence > 0.2
- **ASSEZ SÃ›R**: DiffÃ©rence > 0.05
- **PEU SÃ›R**: DiffÃ©rence > 0
- **HÃ‰SITANT**: Plusieurs coups Ã©quivalents

---

## ðŸŽ² Variantes de Jeu

### Morpion 4x4

**RÃ¨gles:**
- Plateau 4Ã—4 (16 cases)
- Toujours 3 alignÃ©s pour gagner
- Plus de possibilitÃ©s stratÃ©giques

**Utilisation:**
```python
from engine.environment_extended import TicTacToeExtended

env = TicTacToeExtended(board_size=4, win_length=3)
```

### Morpion 5x5

**RÃ¨gles:**
- Plateau 5Ã—5 (25 cases)
- 3 alignÃ©s pour gagner
- Jeu beaucoup plus complexe

```python
env = TicTacToeExtended(board_size=5, win_length=3)
```

### Ultimate Tic-Tac-Toe

**RÃ¨gles:**
- 9 plateaux 3Ã—3 dans un grand plateau 3Ã—3
- Quand vous jouez dans une case, cela dÃ©termine le sous-plateau oÃ¹ l'adversaire doit jouer
- Gagnez 3 sous-plateaux alignÃ©s pour gagner le jeu

```python
from engine.environment_extended import UltimateTicTacToe

env = UltimateTicTacToe()
```

### Variantes avec Contraintes

**Centre interdit:**
```python
from engine.environment_extended import MorpionVariants

env = TicTacToeExtended(board_size=3)
# VÃ©rifier avant chaque coup:
if not MorpionVariants.no_center_rule(env):
    print("Le centre est interdit!")
```

**Coins obligatoires (premiers coups):**
```python
legal_actions = MorpionVariants.corners_first_rule(env, moves_count)
```

---

## ðŸ“Š Visualisations

### Q-table Heatmap

**Description:**
Affiche les Q-values sous forme de carte de chaleur colorÃ©e.

**Utilisation:**
```python
from rl_logic.visualization import QTableVisualizer

visualizer = QTableVisualizer(screen, assets)
visualizer.draw_q_values_for_state(board, q_values)
```

**Couleurs:**
- ðŸŸ¢ Vert: Q-value Ã©levÃ©e (bon coup)
- ðŸŸ¡ Jaune: Q-value moyenne
- ðŸ”µ Bleu: Q-value faible (mauvais coup)

### Graphiques d'EntraÃ®nement

**Temps RÃ©el:**
```python
from rl_logic.visualization import RealtimeTrainingVisualization

viz = RealtimeTrainingVisualization(screen, assets)
viz.update(episode, win_rate, epsilon)
viz.draw()
```

**Post-EntraÃ®nement:**
```python
from rl_logic.visualization import TrainingGraphs

graph = TrainingGraphs.create_training_progress_graph(
    episodes, win_rates, epsilons
)
screen.blit(graph, (0, 0))
```

### Dashboard Comparatif

**Description:**
Compare visuellement les performances de tous les modÃ¨les.

```python
graph = TrainingGraphs.create_metrics_comparison_chart(models_data)
```

Affiche un graphique en barres avec:
- ðŸŸ¢ Vert: Score â‰¥ 80
- ðŸŸ  Orange: Score â‰¥ 60
- ðŸ”´ Rouge: Score < 60

---

## ðŸ… SystÃ¨me ELO

### Principe

Le systÃ¨me ELO (comme aux Ã©checs) classe les modÃ¨les selon leurs performances en match:
- Rating initial: **1500**
- Victoire: Gagne des points ELO
- DÃ©faite: Perd des points ELO
- Les points gagnÃ©s/perdus dÃ©pendent de la diffÃ©rence de rating

### Formule

```
Score attendu = 1 / (1 + 10^((Rating_B - Rating_A) / 400))
Nouveau rating = Rating ancien + K Ã— (Score rÃ©el - Score attendu)
```

OÃ¹:
- **K = 32** (facteur de sensibilitÃ©)
- **Score rÃ©el**: 1 (victoire), 0.5 (nul), 0 (dÃ©faite)

### Exemple

```
Avant match:
  Model A: 1500 ELO
  Model B: 1600 ELO

Score attendu pour A: 0.36 (36% de chances de gagner)

Si A gagne:
  Nouveau rating A: 1500 + 32 Ã— (1 - 0.36) = 1520 (+20)
  Nouveau rating B: 1600 + 32 Ã— (0 - 0.64) = 1580 (-20)
```

### Classement

```bash
python run_tournament.py
# AprÃ¨s le tournoi, voir le classement ELO
```

**Fichier de sauvegarde:** `models/elo_ratings.json`

---

## ðŸ’» Commandes et Utilisation

### Installation

```bash
# CrÃ©er l'environnement virtuel
python -m venv venv

# Activer (Windows)
venv\Scripts\activate

# Activer (Linux/Mac)
source venv/bin/activate

# Installer les dÃ©pendances
pip install -r requirements.txt
```

### Lancer l'Interface GUI

```bash
python run.py
```

### Scripts SpÃ©cialisÃ©s

**Tournoi:**
```bash
python run_tournament.py
```

**AutoML:**
```bash
python run_automl.py
```

**Analyse de modÃ¨les:**
```bash
python analyze_models.py
```

**Rebuild metadata (si nÃ©cessaire):**
```bash
python rebuild_metadata.py
```

### Raccourcis Clavier (en jeu)

- `C`: Toggle Mode Coach
- `D`: Toggle Mode Debug (affiche Q-values)
- `ESPACE`: Rejouer (aprÃ¨s une partie)
- `ECHAP`: Retour au menu

---

## ðŸ“ˆ MÃ©triques DÃ©taillÃ©es

Voir `METRICS_GUIDE.md` pour les dÃ©tails complets des mÃ©triques.

### RÃ©sumÃ© Rapide

| MÃ©trique | Description | Formule | Bon Score |
|----------|-------------|---------|-----------|
| **Performance** | Victoires + nuls | `win_rate + 0.5Ã—draw_rate` | > 80% |
| **Efficiency** | EfficacitÃ© d'apprentissage | `win_rate / log(states)` | > 10 |
| **Robustness** | StabilitÃ© | `avg_reward Ã— factor` | > 0.5 |
| **Learning Speed** | Vitesse d'apprentissage | `win_rate / log(episodes)` | > 8 |
| **Composite** | Score global | `0.4Ã—P + 0.25Ã—E + 0.2Ã—R + 0.15Ã—L` | > 70 |

---

## ðŸŽ“ Pour Aller Plus Loin

### Optimiser un ModÃ¨le

1. **AutoML** pour trouver les meilleurs hyperparamÃ¨tres
2. **EntraÃ®ner** avec ces hyperparamÃ¨tres (50k-100k Ã©pisodes)
3. **Tournoi** pour valider les performances
4. **Coach** pour analyser la stratÃ©gie

### CrÃ©er un ModÃ¨le Champion

```bash
# 1. Optimiser les hyperparamÃ¨tres
python run_automl.py
# Choisir Random Search, 30 itÃ©rations, 15000 Ã©pisodes

# 2. Noter la meilleure config (ex: alpha=0.18, gamma=0.97, decay=0.9975)

# 3. EntraÃ®ner un modÃ¨le final
python run.py
# Menu â†’ EntraÃ®nement Rapide
# Entrer 100000 Ã©pisodes

# 4. Tester en tournoi
python run_tournament.py
# Round-Robin avec tous les modÃ¨les

# 5. Analyser avec le Coach
python run.py
# Mode Coach activÃ©, jouer contre le modÃ¨le
```

---

## ðŸ“ Structure des Fichiers

```
Projet_RL_JEU_Morpion/
â”œâ”€â”€ engine/
â”‚   â”œâ”€â”€ environment.py          # Environnement 3x3 classique
â”‚   â””â”€â”€ environment_extended.py # Variantes 4x4, 5x5, Ultimate
â”œâ”€â”€ rl_logic/
â”‚   â”œâ”€â”€ agent.py                # Agent Q-Learning
â”‚   â”œâ”€â”€ trainer.py              # EntraÃ®nement
â”‚   â”œâ”€â”€ metrics.py              # Calcul des mÃ©triques
â”‚   â”œâ”€â”€ model_comparator.py     # Comparaison de modÃ¨les
â”‚   â”œâ”€â”€ model_manager.py        # Gestion des modÃ¨les
â”‚   â”œâ”€â”€ elo_system.py           # SystÃ¨me ELO
â”‚   â”œâ”€â”€ tournament.py           # Tournois
â”‚   â”œâ”€â”€ automl.py               # AutoML
â”‚   â”œâ”€â”€ coach.py                # Mode Coach
â”‚   â””â”€â”€ visualization.py        # Visualisations
â”œâ”€â”€ gui/
â”‚   â”œâ”€â”€ pygame_app.py           # Application principale
â”‚   â”œâ”€â”€ view_game.py            # Vue du jeu
â”‚   â”œâ”€â”€ view_stats.py           # Vue statistiques
â”‚   â”œâ”€â”€ view_models.py          # Gestion des modÃ¨les
â”‚   â”œâ”€â”€ view_tournament.py      # Interface tournoi
â”‚   â””â”€â”€ view_automl.py          # Interface AutoML
â”œâ”€â”€ models/                     # ModÃ¨les sauvegardÃ©s
â”‚   â”œâ”€â”€ *.pkl                   # Fichiers de modÃ¨les
â”‚   â”œâ”€â”€ models_metadata.json    # MÃ©tadonnÃ©es
â”‚   â”œâ”€â”€ elo_ratings.json        # Ratings ELO
â”‚   â”œâ”€â”€ tournament_history.json # Historique tournois
â”‚   â””â”€â”€ automl_results.csv      # RÃ©sultats AutoML
â”œâ”€â”€ logs/                       # Logs et historiques
â”œâ”€â”€ run.py                      # Lancer le GUI
â”œâ”€â”€ run_tournament.py           # Lancer un tournoi
â”œâ”€â”€ run_automl.py               # Lancer AutoML
â”œâ”€â”€ FEATURES_GUIDE.md          # Ce fichier
â””â”€â”€ METRICS_GUIDE.md           # Guide des mÃ©triques
```

---

## ðŸŽ¯ Bonnes Pratiques

### Pour l'EntraÃ®nement

1. **Commencer petit**: 10k Ã©pisodes pour tester
2. **Augmenter progressivement**: 50k, 100k, 200k
3. **Sauvegarder rÃ©guliÃ¨rement**: Ne perdez pas vos progrÃ¨s
4. **Comparer**: Utilisez les mÃ©triques pour Ã©valuer

### Pour les Tournois

1. **SÃ©lectionner 5-10 modÃ¨les**: Ne surchargez pas
2. **100 parties/match minimum**: Pour des rÃ©sultats statistiques fiables
3. **Round-Robin pour classement**: Ã‰limination pour le fun
4. **Analyser les rÃ©sultats**: Qui bat qui ? Pourquoi ?

### Pour l'AutoML

1. **Random Search d'abord**: Plus rapide, bonnes approximations
2. **Grid Search autour des meilleurs**: Affiner
3. **Plusieurs exÃ©cutions**: La randomisation peut varier les rÃ©sultats
4. **Garder un log**: Notez les meilleures configs

---

## ðŸ› DÃ©pannage

### L'IA joue mal

- VÃ©rifiez epsilon (doit Ãªtre proche de 0 pour Expert)
- Le modÃ¨le a-t-il assez d'Ã©tats appris ? (>100)
- EntraÃ®nez plus longtemps

### AutoML lent

- RÃ©duisez le nombre d'Ã©pisodes (5k-10k pour tests rapides)
- Utilisez Grid Fast au lieu de Grid Full
- Random Search avec moins d'itÃ©rations (10-15)

### Tournoi ne se lance pas

- Au moins 2 modÃ¨les requis
- VÃ©rifiez que les modÃ¨les se chargent (`models_view`)
- Regardez les logs dans `logs/`

### Mode Coach ne s'affiche pas

- Appuyez sur `C` pendant une partie
- VÃ©rifiez que vous jouez contre l'IA (Humain vs IA)
- L'agent doit avoir des Ã©tats appris

---

## ðŸ“ž Support

Pour toute question ou problÃ¨me:
1. Consultez `METRICS_GUIDE.md` pour les mÃ©triques
2. VÃ©rifiez les logs dans `logs/`
3. Testez avec `test_metrics.py` et `test_display.py`

---

## ðŸš€ Roadmap Future (IdÃ©es)

- [ ] Interface web (Flask/Streamlit)
- [ ] Deep Q-Learning (DQN)
- [ ] Multijoueur en ligne
- [ ] Analyse vidÃ©o des parties
- [ ] Export des tournois en PDF
- [ ] Replay animÃ© des parties
- [ ] Bracket visualization graphique
- [ ] Mode spectateur avec commentaires IA

---

**Bon jeu et bon apprentissage ! ðŸŽ®ðŸ¤–**
