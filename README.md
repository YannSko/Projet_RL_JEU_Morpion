# ğŸ® Morpion Q-Learning - Intelligence Artificielle par Apprentissage par Renforcement

[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![Pygame](https://img.shields.io/badge/pygame--ce-2.5+-green.svg)](https://github.com/pygame-community/pygame-ce)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)

Projet acadÃ©mique complet d'**Apprentissage par Renforcement (RL)** appliquÃ© au jeu de Morpion. Interface graphique moderne, systÃ¨me de tournoi, optimisation automatique des hyperparamÃ¨tres (AutoML), mÃ©triques avancÃ©es et mode Coach IA pour l'explainability.

---

## ğŸ“‹ Table des MatiÃ¨res

- [âœ¨ FonctionnalitÃ©s](#-fonctionnalitÃ©s)
- [ğŸš€ DÃ©marrage Rapide](#-dÃ©marrage-rapide)
- [ğŸ¯ Modes de Jeu](#-modes-de-jeu)
- [ğŸ§  MÃ©triques d'Ã‰valuation](#-mÃ©triques-dÃ©valuation)
- [ğŸ† SystÃ¨me de Tournoi](#-systÃ¨me-de-tournoi)
- [ğŸ¤– AutoML](#-automl)
- [ğŸ§‘â€ğŸ« Mode Coach](#-mode-coach)
- [ğŸ¨ Interface Moderne](#-interface-moderne)
- [ğŸ“ Architecture](#-architecture)
- [ğŸ“– Documentation](#-documentation)
- [ğŸ› ï¸ Technologies](#ï¸-technologies)

---

## âœ¨ FonctionnalitÃ©s

### ğŸ² **Jeu Complet**
- **5 modes de jeu** : Humain vs Humain, Humain vs IA, IA vs IA, EntraÃ®nement, Coach
- **3 niveaux de difficultÃ©** : DÃ©butant (Îµ=0.5), IntermÃ©diaire (Îµ=0.2), Expert (Îµ=0)
- **Interface moderne** : ThÃ¨me sombre Ã©lÃ©gant avec effets visuels (glow, ombres, dÃ©gradÃ©s)

### ğŸ§  **Apprentissage par Renforcement**
- **Algorithme Q-Learning** : Off-policy TD control avec exploration Îµ-greedy
- **MÃ©triques avancÃ©es** : 10+ mÃ©triques incluant Bellman Error, TD Error, Sample Efficiency
- **Multi-seed evaluation** : Ã‰valuation robuste avec 3-5 seeds diffÃ©rentes
- **SÃ©paration train/eval** : MÃ©triques calculÃ©es en post-training avec Îµ=0

### ğŸ† **SystÃ¨me CompÃ©titif**
- **Tournois automatiques** : Round-Robin et Ã‰limination directe
- **Classement ELO** : SystÃ¨me de rating style Ã©checs (1500Â±200 points)
- **218+ modÃ¨les** : BibliothÃ¨que de modÃ¨les prÃ©-entraÃ®nÃ©s

### ğŸ¤– **Optimisation Automatique**
- **AutoML intÃ©grÃ©** : Grid Search et Random Search
- **Optimisation multi-critÃ¨res** : Composite Score, Sample Efficiency, Bellman Error
- **Configuration flexible** : Espaces d'hyperparamÃ¨tres personnalisables

### ğŸ§‘â€ğŸ« **Explainability**
- **Mode Coach IA** : Suggestions en temps rÃ©el du meilleur coup
- **Visualisation Q-values** : Affichage colorÃ© des scores de chaque case
- **Explications stratÃ©giques** : Raisons du choix (attaque, dÃ©fense, blocage)
- **Niveau de confiance** : Ã‰valuation de la certitude de l'IA

### ğŸ“Š **Analyse et Visualisation**
- **Historique complet** : Toutes les parties sauvegardÃ©es
- **Graphiques dÃ©taillÃ©s** : Ã‰volution des performances, learning curves
- **Statistiques avancÃ©es** : Win rate, moyenne, std, coefficient de variation
- **Export de donnÃ©es** : JSON, CSV pour analyse externe

---

## ğŸš€ DÃ©marrage Rapide

### PrÃ©requis
- **Python 3.9+** (testÃ© avec Python 3.14)
- **pip** pour l'installation des dÃ©pendances

### Installation

```bash
# 1. Cloner le dÃ©pÃ´t
git clone <votre-repo>
cd Projet_RL_JEU_Morpion

# 2. CrÃ©er environnement virtuel (recommandÃ©)
python -m venv venv

# Windows
venv\Scripts\activate

# Linux/Mac
source venv/bin/activate

# 3. Installer les dÃ©pendances
pip install -r requirements.txt
```

### Lancement Rapide

```bash
# Interface graphique principale
python run.py

# Lancer un tournoi
python run_tournament.py

# Optimiser les hyperparamÃ¨tres
python run_automl.py

# Analyser tous les modÃ¨les
python analyze_models.py

# Afficher mÃ©triques dÃ©taillÃ©es
python display_rl_metrics.py
```

---

## ğŸ¯ Modes de Jeu

### ğŸ‘¥ **Humain vs Humain**
Jouez Ã  deux sur le mÃªme ordinateur. IdÃ©al pour tester l'interface.

### ğŸ® **Humain vs IA**
Affrontez l'IA avec 3 niveaux de difficultÃ© :
- **ğŸŒ± DÃ©butant** : Îµ=0.5 (50% alÃ©atoire)
- **âš¡ IntermÃ©diaire** : Îµ=0.2 (20% alÃ©atoire)
- **ğŸ”¥ Expert** : Îµ=0 (politique optimale pure)

**Raccourci** : Appuyez sur **C** pour activer le Mode Coach et voir les suggestions de l'IA

### ğŸ¤– **IA vs IA**
Regardez deux IAs s'affronter pour comparer les stratÃ©gies.

### âš¡ **EntraÃ®nement Rapide**
Interface de configuration des hyperparamÃ¨tres :
- Nombre d'Ã©pisodes : 1,000 - 1,000,000
- Learning rate (Î±) : 0.01 - 1.0
- Discount factor (Î³) : 0.5 - 0.99
- Epsilon decay : linÃ©aire ou exponentiel
- Post-training evaluation avec multi-seed

### ğŸ§  **Gestion des ModÃ¨les**
- **Liste complÃ¨te** : 218+ modÃ¨les disponibles
- **Tri multi-critÃ¨res** : Composite Score, Sample Efficiency, Bellman Error
- **DÃ©tails complets** : HyperparamÃ¨tres, mÃ©triques, historique
- **Actions** : Charger, renommer, supprimer, importer

---

## ğŸ§  MÃ©triques d'Ã‰valuation

Le projet implÃ©mente **10 mÃ©triques** pour Ã©valuer la qualitÃ© des modÃ¨les RL :

### ğŸ“Š **MÃ©triques Classiques**

| MÃ©trique | Description | Formule | Bon Score |
|----------|-------------|---------|-----------|
| **Performance Score** | Taux de victoire + bonus nuls | `win_rate + 0.5 Ã— draw_rate` | **> 85%** |
| **Efficiency Score** | Ratio perf/complexitÃ© | `win_rate / log(states + 1)` | **> 10** |
| **Learning Speed** | Vitesse d'apprentissage | `win_rate / log(episodes + 1)` | **> 8** |
| **Robustness Score** | StabilitÃ© de la politique | `avg_reward Ã— robustness_factor` | **> 0.6** |

### ğŸ§  **MÃ©triques RL AvancÃ©es** (Nouvelles)

| MÃ©trique | Signification | InterprÃ©tation | Bon Score |
|----------|---------------|----------------|-----------|
| **Bellman Error** | Convergence de la Q-table | Erreur moyenne sur Ã©quation de Bellman | **< 0.1** |
| **TD Error Mean** | Biais d'apprentissage | Moyenne des erreurs TD | **< 0.15** |
| **TD Error Variance** | StabilitÃ© apprentissage | Variance des erreurs TD | **< 0.3** |
| **Return Variance** | Consistance de la politique | Variance des retours cumulÃ©s | **< 0.4** |
| **Sample Efficiency** | EfficacitÃ© d'apprentissage | `win_rate / (episodes / 1000)` | **> 5.0** |
| **Policy Entropy** | DÃ©terminisme (0 = optimal) | Entropie de la politique Ï€(s) | **< 0.5** |

### ğŸ¯ **Score Global**

**Composite Score** : Score pondÃ©rÃ© combinant toutes les mÃ©triques
- **PondÃ©ration** : Performance (35%), Efficiency (20%), RL metrics (45%)
- **Ã‰chelle** : 0-100
- **Excellence** : > 75
- **Bon** : 60-75
- **Acceptable** : 50-60

### ğŸ“ˆ **Ã‰valuation Multi-Seed**

Chaque modÃ¨le est Ã©valuÃ© avec **3-5 seeds diffÃ©rentes** pour garantir la robustesse :
- **Moyenne** : Performance moyenne sur tous les seeds
- **Ã‰cart-type** : Mesure de la variabilitÃ©
- **Min/Max** : Pire et meilleur cas
- **CV** (Coefficient de Variation) : StabilitÃ© relative (< 5% = excellent)

**Exemple** :
```
Win Rate: 86.1% Â± 0.7%  (min: 85.5%, max: 86.8%, CV: 0.8%)
        â†“         â†“                               â†“
     moyenne   Ã©cart-type                    trÃ¨s stable
```

**Documentation complÃ¨te** : [docs/METRICS_GUIDE.md](docs/METRICS_GUIDE.md)

---

## ğŸ† SystÃ¨me de Tournoi

### **Types de Tournois**

#### ğŸ”„ **Round-Robin**
Chaque modÃ¨le affronte tous les autres :
- **Nombre de matchs** : nÃ—(n-1)/2 pour n modÃ¨les
- **Parties par match** : Configurable (50-500)
- **Classement** : Par victoires puis diffÃ©rence de buts
- **DurÃ©e** : ~2-10 minutes selon modÃ¨les

#### ğŸ… **Ã‰limination Directe**
Bracket Ã  Ã©limination (8, 16, 32 modÃ¨les) :
- **Format** : Single elimination
- **Seed automatique** : Par ELO rating
- **Best-of** : 1, 3 ou 5 parties
- **Finales** : Demi-finales, petite finale, grande finale

### **SystÃ¨me ELO**

Chaque modÃ¨le a un **rating ELO** actualisÃ© aprÃ¨s chaque partie :

```python
# Formule
new_rating = old_rating + K Ã— (score - expected_score)

# ParamÃ¨tres
K = 32              # Facteur de changement
Initial = 1500      # Rating de dÃ©part
Score = 1 / 0.5 / 0 # Victoire / Nul / DÃ©faite
```

**Classement typique** :
- **ğŸ† Ã‰lite** : > 1700 (top 5%)
- **â­ Expert** : 1600-1700 (top 20%)
- **âœ… Bon** : 1500-1600 (moyenne)
- **ğŸ“š En apprentissage** : < 1500

**Sauvegarde** : `models/elo_ratings.json`

**Lancer un tournoi** :
```bash
python run_tournament.py
# Choisir le type et la configuration dans l'interface
```

---

## ğŸ¤– AutoML

Optimisation automatique des hyperparamÃ¨tres pour trouver la meilleure configuration.

### **Algorithmes Disponibles**

#### ğŸ” **Grid Search**
Teste toutes les combinaisons possibles :
- **Grid Fast** : Espace rÃ©duit (2-3 valeurs/paramÃ¨tre) â†’ ~100 configs
- **Grid Full** : Espace complet (5-7 valeurs/paramÃ¨tre) â†’ ~1000 configs
- **Avantage** : Exhaustif, trouve l'optimum global
- **InconvÃ©nient** : Lent pour grands espaces

#### ğŸ² **Random Search**
Ã‰chantillonnage alÃ©atoire intelligent :
- **Iterations** : 10-50 (configurable)
- **Distribution** : Uniforme ou log-uniforme selon le paramÃ¨tre
- **Avantage** : Rapide, bonne approximation
- **InconvÃ©nient** : Peut manquer l'optimum

### **Espaces d'HyperparamÃ¨tres**

```python
# Configuration typique
alpha (learning rate):     [0.01, 0.05, 0.1, 0.3, 0.5, 0.7, 0.9]
gamma (discount factor):   [0.5, 0.7, 0.85, 0.9, 0.95, 0.99]
epsilon_start:             [0.8, 0.9, 1.0]
epsilon_min:               [0.001, 0.01, 0.05]
epsilon_decay:             [0.995, 0.998, 0.999, 0.9995]
```

### **CritÃ¨res d'Optimisation**

Trois critÃ¨res principaux (sÃ©lectionnable) :
1. **Composite Score** : Score global (dÃ©faut)
2. **Sample Efficiency** : Meilleur rapport performance/coÃ»t
3. **Bellman Error** : Meilleure convergence

### **Workflow AutoML**

```bash
# 1. Lancer AutoML
python run_automl.py

# 2. Choisir algorithme
#    â†’ Random Search (rapide, recommandÃ©)
#    â†’ Grid Fast (exhaustif, moyen)

# 3. Configuration
#    Iterations: 20
#    Episodes: 10,000-50,000
#    Criterion: composite_score

# 4. Attendre rÃ©sultats
#    Progression en temps rÃ©el
#    Meilleur modÃ¨le sauvegardÃ© automatiquement

# 5. Charger le modÃ¨le optimisÃ©
#    models/automl_best_YYYYMMDD_HHMMSS.pkl
```

**DurÃ©e typique** :
- Random Search (20 iter, 10k ep) : **~5-10 min**
- Grid Fast (100 configs, 10k ep) : **~30-60 min**
- Grid Full (1000 configs, 50k ep) : **~6-12 heures**

**Documentation** : [docs/FEATURES_GUIDE.md](docs/FEATURES_GUIDE.md)

---

## ğŸ§‘â€ğŸ« Mode Coach

Assistant IA en temps rÃ©el pour apprendre la stratÃ©gie optimale du Morpion.

### **Activation**
Appuyez sur **C** pendant une partie (Humain vs IA)

### **Panneau Coach** (boÃ®te jaune)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   COACH IA          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Coup: (1, 2)        â”‚  â† Position recommandÃ©e
â”‚ Q-value: 0.948      â”‚  â† Score du coup (0-1)
â”‚ CONFIANT            â”‚  â† Niveau de confiance
â”‚ âœ“ Excellent coup    â”‚  â† Explication stratÃ©gique
â”‚ âš¡ Bloque victoire   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Q-Values sur la Grille**

Chaque case vide affiche son **score Q** avec code couleur :
- ğŸŸ¢ **Vert** (Q > 0.7) : Excellent coup
- ğŸŸ¡ **Jaune** (0.3 < Q < 0.7) : Coup moyen
- ğŸ”´ **Rouge** (Q < 0.3) : Mauvais coup

**Exemple** :
```
â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”
â”‚  X  â”‚     â”‚  O  â”‚
â”‚     â”‚0.946â”‚0.403â”‚  â† Q-values affichÃ©s
â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¤
â”‚     â”‚0.948â”‚     â”‚
â”‚0.191â”‚     â”‚     â”‚  â† 0.191 = mauvais
â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¤
â”‚     â”‚     â”‚     â”‚
â”‚0.170â”‚0.175â”‚0.485â”‚
â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”˜
```

### **Explications StratÃ©giques**

Le Coach fournit des raisons contextuelles :
- **"Bloque victoire adverse"** : DÃ©fense urgente
- **"CrÃ©e double menace"** : Coup offensif fort
- **"Prend le centre"** : StratÃ©gie positionnelle
- **"Force la main"** : ContrÃ´le du jeu

### **Utilisation PÃ©dagogique**

1. **Jouez naturellement** : Faites votre coup instinctif
2. **Comparez** : Regardez la suggestion du Coach
3. **Analysez** : Comprenez pourquoi l'alternative est meilleure
4. **Apprenez** : IntÃ©grez les patterns stratÃ©giques

**Raccourcis** :
- **C** : Toggle Coach (on/off)
- **D** : Toggle Debug (affiche tous les Q-values)

---

## ğŸ¨ Interface Moderne

### **Design Dark Mode Ã‰lÃ©gant**

- **Palette** : Bleu nuit profond (#141923) avec accents cyan et corail
- **Symboles** :
  - âŒ **X** : Rouge corail (#ED6A5E) avec effet glow
  - â­• **O** : Bleu cyan (#63B3ED) avec effet glow
- **Grille** : Lignes avec effet glow subtil pour profondeur

### **Effets Visuels**

#### Boutons Modernes
- **Ombres portÃ©es** : Profondeur visuelle
- **Bordures arrondies** : 12px radius
- **Hover animÃ©** : Changement de couleur + Ã©lÃ©vation
- **4 styles** : primary (bleu), success (vert), danger (rouge), neutral (gris)

#### Cartes (Cards)
- Fond semi-transparent avec blur
- Barre latÃ©rale colorÃ©e pour accentuation
- Organisation claire label/valeur
- Effet hover avec bordure lumineuse

#### Barres de Progression
- DÃ©gradÃ©s horizontaux
- Highlight 3D en haut
- Texte avec ombre pour lisibilitÃ©

### **Typographie**

HiÃ©rarchie claire avec 5 niveaux :
- **Title** : 56px - Titres principaux
- **Large** : 42px - Sous-titres
- **Medium** : 32px - Texte important
- **Small** : 24px - Texte normal
- **Tiny** : 18px - DÃ©tails

### **Responsive**

- FenÃªtre : **900Ã—1050px** (ajustÃ©e pour tous les boutons)
- Dimensionnement dynamique selon `window_size`
- Support multi-rÃ©solutions

**Documentation UI** : [docs/UI_IMPROVEMENTS.md](docs/UI_IMPROVEMENTS.md)

---

## ğŸ“ Architecture

```
Projet_RL_JEU_Morpion/
â”‚
â”œâ”€â”€ ğŸ“‚ engine/                    # Environnements de jeu
â”‚   â”œâ”€â”€ environment.py            # Morpion 3x3 classique
â”‚   â”œâ”€â”€ environment_extended.py   # Variantes 4x4, 5x5, Ultimate
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ ğŸ“‚ rl_logic/                  # Logique d'apprentissage
â”‚   â”œâ”€â”€ agent.py                  # Q-Learning Agent
â”‚   â”œâ”€â”€ trainer.py                # EntraÃ®nement et Ã©valuation
â”‚   â”œâ”€â”€ metrics.py                # Calcul des 10 mÃ©triques
â”‚   â”œâ”€â”€ model_manager.py          # Gestion des modÃ¨les
â”‚   â”œâ”€â”€ model_comparator.py       # Comparaison de modÃ¨les
â”‚   â”œâ”€â”€ elo_system.py             # SystÃ¨me de rating ELO
â”‚   â”œâ”€â”€ tournament.py             # Tournois Round-Robin/Elimination
â”‚   â”œâ”€â”€ automl.py                 # Optimisation hyperparamÃ¨tres
â”‚   â”œâ”€â”€ coach.py                  # Mode Coach IA
â”‚   â”œâ”€â”€ visualization.py          # Graphiques et plots
â”‚   â”œâ”€â”€ logger.py                 # Logging RL
â”‚   â”œâ”€â”€ app_logger.py             # Logging application
â”‚   â”œâ”€â”€ game_logger.py            # Logging parties
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ ğŸ“‚ gui/                       # Interface Pygame
â”‚   â”œâ”€â”€ pygame_app.py             # Application principale
â”‚   â”œâ”€â”€ assets.py                 # Couleurs, polices, dessins
â”‚   â”œâ”€â”€ view_game.py              # Interface de jeu
â”‚   â”œâ”€â”€ view_stats.py             # Statistiques et graphiques
â”‚   â”œâ”€â”€ view_history.py           # Historique des parties
â”‚   â”œâ”€â”€ view_models.py            # Gestion des modÃ¨les
â”‚   â”œâ”€â”€ view_tournament.py        # Interface tournoi
â”‚   â”œâ”€â”€ view_automl.py            # Interface AutoML
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ ğŸ“‚ models/                    # ModÃ¨les sauvegardÃ©s (218+)
â”‚   â”œâ”€â”€ q_table.pkl               # ModÃ¨le par dÃ©faut
â”‚   â”œâ”€â”€ best_score.pkl            # Meilleur composite score
â”‚   â”œâ”€â”€ sample_eff_best.pkl       # Meilleur sample efficiency
â”‚   â”œâ”€â”€ elo_ratings.json          # Classement ELO
â”‚   â”œâ”€â”€ models_metadata.json      # MÃ©tadonnÃ©es tous modÃ¨les
â”‚   â””â”€â”€ tournament_history.json   # Historique tournois
â”‚
â”œâ”€â”€ ğŸ“‚ logs/                      # Logs et historiques
â”‚   â”œâ”€â”€ training_stats.csv        # Stats d'entraÃ®nement
â”‚   â”œâ”€â”€ game_history.json         # Toutes les parties
â”‚   â””â”€â”€ evaluation_results.json   # RÃ©sultats Ã©valuations
â”‚
â”œâ”€â”€ ğŸ“‚ docs/                      # Documentation dÃ©taillÃ©e
â”‚   â”œâ”€â”€ FEATURES_GUIDE.md         # Guide complet des features
â”‚   â”œâ”€â”€ METRICS_GUIDE.md          # Documentation mÃ©triques
â”‚   â”œâ”€â”€ METRICS_CLASSIFICATION.md # Classification mÃ©triques
â”‚   â”œâ”€â”€ UI_IMPROVEMENTS.md        # AmÃ©liorations interface
â”‚   â”œâ”€â”€ TRAIN_EVAL_FIXED.md       # SÃ©paration train/eval
â”‚   â”œâ”€â”€ MULTI_SEED_EVAL.md        # Ã‰valuation multi-seed
â”‚   â”œâ”€â”€ SORT_SYSTEM_GUIDE.md      # SystÃ¨me de tri
â”‚   â””â”€â”€ IMPLEMENTATION_SUMMARY.md # RÃ©sumÃ© implÃ©mentation
â”‚
â”œâ”€â”€ ğŸ“œ run.py                     # Lancer GUI principal
â”œâ”€â”€ ğŸ“œ run_tournament.py          # Lancer un tournoi
â”œâ”€â”€ ğŸ“œ run_automl.py              # Lancer AutoML
â”œâ”€â”€ ğŸ“œ analyze_models.py          # Analyser tous les modÃ¨les
â”œâ”€â”€ ğŸ“œ display_rl_metrics.py      # Afficher mÃ©triques dÃ©taillÃ©es
â”œâ”€â”€ ğŸ“œ rebuild_metadata.py        # Reconstruire mÃ©tadonnÃ©es
â”œâ”€â”€ ğŸ“œ test_metrics.py            # Tests mÃ©triques
â”œâ”€â”€ ğŸ“œ test_display.py            # Tests affichage
â”œâ”€â”€ ğŸ“œ requirements.txt           # DÃ©pendances Python
â”œâ”€â”€ ğŸ“œ LICENSE                    # Licence MIT
â””â”€â”€ ğŸ“œ README.md                  # Ce fichier
```

---

## ğŸ“– Documentation

### **Guides Complets**

- **[docs/FEATURES_GUIDE.md](docs/FEATURES_GUIDE.md)** - Guide dÃ©taillÃ© de toutes les fonctionnalitÃ©s
- **[docs/METRICS_GUIDE.md](docs/METRICS_GUIDE.md)** - Documentation complÃ¨te des 10 mÃ©triques
- **[docs/UI_IMPROVEMENTS.md](docs/UI_IMPROVEMENTS.md)** - Design moderne et palette de couleurs
- **[docs/TRAIN_EVAL_FIXED.md](docs/TRAIN_EVAL_FIXED.md)** - SÃ©paration train/eval et bonnes pratiques
- **[docs/MULTI_SEED_EVAL.md](docs/MULTI_SEED_EVAL.md)** - Ã‰valuation robuste multi-seed

### **Documentation Technique**

- **[docs/METRICS_CLASSIFICATION.md](docs/METRICS_CLASSIFICATION.md)** - Classification dÃ©taillÃ©e des mÃ©triques
- **[docs/SORT_SYSTEM_GUIDE.md](docs/SORT_SYSTEM_GUIDE.md)** - SystÃ¨me de tri multi-critÃ¨res
- **[docs/IMPLEMENTATION_SUMMARY.md](docs/IMPLEMENTATION_SUMMARY.md)** - RÃ©sumÃ© de l'architecture

---

## ğŸ› ï¸ Technologies

### **Backend**
- **Python 3.9+** (testÃ© jusqu'Ã  3.14)
- **NumPy** - Calculs matriciels et Q-table
- **Pandas** - Analyse de donnÃ©es et statistiques
- **Matplotlib** - Visualisations et graphiques

### **Frontend**
- **Pygame-CE 2.5+** - Interface graphique moderne
  - Rendu 2D accÃ©lÃ©rÃ©
  - Gestion Ã©vÃ©nements
  - Animations fluides

### **Machine Learning**
- **Q-Learning** - Algorithme de base (from scratch)
- **Îµ-greedy** - StratÃ©gie d'exploration
- **Bellman Equation** - Mise Ã  jour valeurs Q
- **TD Learning** - Temporal Difference

### **Outils**
- **JSON** - Sauvegarde modÃ¨les et mÃ©tadonnÃ©es
- **Pickle** - SÃ©rialisation Q-tables
- **CSV** - Export statistiques

---

## ğŸ› DÃ©pannage

### **L'IA joue mal**
- âœ… VÃ©rifiez `epsilon` : doit Ãªtre ~0.01 pour Expert
- âœ… Ã‰tats appris : minimum 2000-3000
- âœ… EntraÃ®nez plus longtemps : 50k-100k Ã©pisodes

### **AutoML trop lent**
- âœ… RÃ©duisez les Ã©pisodes : 5k-10k pour tests rapides
- âœ… Utilisez Random Search au lieu de Grid
- âœ… Limitez Ã  10-20 itÃ©rations

### **Erreur "pygame not found"**
```bash
pip install pygame-ce  # Pour Python 3.14+
# ou
pip install pygame     # Pour Python 3.9-3.13
```

### **ModÃ¨les introuvables**
```bash
python rebuild_metadata.py  # Reconstruire l'index
```

### **Performances lentes**
- DÃ©sactivez les effets visuels dans `assets.py`
- RÃ©duisez la frÃ©quence de rafraÃ®chissement (ligne 228 de `pygame_app.py`)

---

## ğŸš€ Roadmap & AmÃ©liorations Futures

### **Court Terme**
- [ ] Interface web (Flask/Streamlit)
- [ ] Export tournois en PDF
- [ ] Replay animÃ© des parties
- [ ] Mode spectateur amÃ©liorÃ©

### **Moyen Terme**
- [ ] Deep Q-Learning (DQN)
- [ ] RÃ©seau de neurones au lieu de Q-table
- [ ] Transfer learning entre variantes
- [ ] Multi-agent RL (Self-play)

### **Long Terme**
- [ ] Policy Gradient Methods (REINFORCE, A3C)
- [ ] AlphaZero-style MCTS
- [ ] Multijoueur en ligne
- [ ] API REST pour intÃ©gration externe

---

## ğŸ“„ Licence

Ce projet est sous licence **MIT**. Voir [LICENSE](LICENSE) pour plus de dÃ©tails.

---

## ğŸ‘¨â€ğŸ’» Auteur & Contributions

**Projet AcadÃ©mique** - Cours de Machine Learning

Ce projet dÃ©montre :
- âœ… ImplÃ©mentation complÃ¨te d'un algorithme RL from scratch
- âœ… Architecture modulaire et maintenable
- âœ… Interface utilisateur professionnelle
- âœ… MÃ©triques rigoureuses et Ã©valuation robuste
- âœ… Optimisation automatique (AutoML)
- âœ… Explainability et pÃ©dagogie (Mode Coach)

---

**ğŸ® Bon jeu et bon apprentissage !**

*Pour dÃ©buter, lancez simplement `python run.py` et explorez les diffÃ©rents modes.*
