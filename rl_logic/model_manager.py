"""
Gestionnaire de mod√®les
G√®re la sauvegarde, le chargement et le versionnage des mod√®les Q-Learning.
"""

import pickle
import json
import os
from datetime import datetime
from typing import Dict, Optional, List
from pathlib import Path


class ModelManager:
    """
    G√®re la persistance des mod√®les Q-Learning.
    Supporte le versionnage automatique avec horodatage.
    """
    
    def __init__(self, models_dir: str = "models"):
        """
        Initialise le gestionnaire de mod√®les.
        
        Args:
            models_dir: R√©pertoire de sauvegarde des mod√®les
        """
        self.models_dir = Path(models_dir)
        self.models_dir.mkdir(exist_ok=True)
        
        # Fichiers par d√©faut
        self.default_model = self.models_dir / "q_table.pkl"
        self.metadata_file = self.models_dir / "models_metadata.json"
        
        # Charger ou cr√©er les m√©tadonn√©es
        self.metadata = self._load_metadata()
    
    def save_model(self, agent, name: Optional[str] = None, 
                   versioned: bool = False, metadata: Optional[Dict] = None) -> str:
        """
        Sauvegarde un mod√®le Q-Learning.
        
        Args:
            agent: Agent QLearningAgent √† sauvegarder
            name: Nom du fichier (sans extension). Si None, utilise le nom par d√©faut.
            versioned: Si True, ajoute un horodatage au nom du fichier
            metadata: M√©tadonn√©es additionnelles √† sauvegarder
        
        Returns:
            Chemin du fichier sauvegard√©
        """
        # G√©n√©rer le nom du fichier
        if name is None:
            filepath = self.default_model
        else:
            if versioned:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"{name}_{timestamp}.pkl"
            else:
                filename = f"{name}.pkl"
            filepath = self.models_dir / filename
        
        # Pr√©parer les donn√©es √† sauvegarder
        model_data = {
            'q_table': agent.get_q_table_copy(),
            'hyperparameters': {
                'alpha': agent.alpha,
                'gamma': agent.gamma,
                'epsilon': agent.epsilon,
                'epsilon_start': agent.epsilon_start,
                'epsilon_min': agent.epsilon_min,
                'epsilon_decay': agent.epsilon_decay
            },
            'stats': agent.get_stats(),
            'timestamp': datetime.now().isoformat(),
            'metadata': metadata or {}
        }
        
        # Sauvegarder avec pickle
        with open(filepath, 'wb') as f:
            pickle.dump(model_data, f)
        
        # Mettre √† jour les m√©tadonn√©es
        self._update_metadata(str(filepath), model_data)
        
        print(f"‚úì Mod√®le sauvegard√©: {filepath}")
        print(f"  √âtats: {model_data['stats']['total_states']}")
        print(f"  Epsilon: {model_data['stats']['epsilon']:.6f}")
        
        return str(filepath)
    
    def load_model(self, agent, filepath: Optional[str] = None) -> bool:
        """
        Charge un mod√®le Q-Learning.
        
        Args:
            agent: Agent QLearningAgent √† charger
            filepath: Chemin du fichier √† charger (utilise le d√©faut si None)
        
        Returns:
            True si le chargement a r√©ussi, False sinon
        """
        if filepath is None:
            filepath = self.default_model
        else:
            filepath = Path(filepath)
        
        try:
            with open(filepath, 'rb') as f:
                model_data = pickle.load(f)
            
            # Charger la Q-table
            agent.load_q_table(model_data['q_table'])
            
            # Restaurer les hyperparam√®tres
            params = model_data['hyperparameters']
            agent.alpha = params['alpha']
            agent.gamma = params['gamma']
            agent.epsilon = params['epsilon']
            agent.epsilon_start = params['epsilon_start']
            agent.epsilon_min = params['epsilon_min']
            agent.epsilon_decay = params['epsilon_decay']
            
            print(f"‚úì Mod√®le charg√©: {filepath}")
            print(f"  √âtats appris: {len(agent.q_table)}")
            print(f"  Epsilon: {agent.epsilon:.6f}")
            print(f"  Date: {model_data.get('timestamp', 'N/A')}")
            
            return True
        
        except FileNotFoundError:
            print(f"‚úó Fichier non trouv√©: {filepath}")
            return False
        except Exception as e:
            print(f"‚úó Erreur lors du chargement: {e}")
            return False
    
    def model_exists(self, filepath: Optional[str] = None) -> bool:
        """
        V√©rifie si un mod√®le existe.
        
        Args:
            filepath: Chemin du mod√®le. Si None, v√©rifie le mod√®le par d√©faut.
        
        Returns:
            True si le mod√®le existe, False sinon
        """
        if filepath is None:
            filepath = self.default_model
        else:
            filepath = Path(filepath)
        
        return filepath.exists()
    
    def list_models(self) -> List[Dict]:
        """
        Liste tous les mod√®les disponibles avec leurs informations.
        Utilise le fichier de m√©tadonn√©es pour de meilleures performances.
        
        Returns:
            Liste de dictionnaires contenant les infos de chaque mod√®le
        """
        models = []
        
        # Recharger les m√©tadonn√©es depuis le fichier
        self.metadata = self._load_metadata()
        
        # Utiliser les m√©tadonn√©es si disponibles
        if self.metadata:
            for filepath, meta in self.metadata.items():
                filepath_obj = Path(filepath)
                if filepath_obj.exists():
                    models.append({
                        'name': filepath_obj.name,
                        'path': str(filepath_obj),
                        'timestamp': meta.get('timestamp', 'N/A'),
                        'states': meta.get('states', 0),
                        'epsilon': meta.get('epsilon', 1.0),
                        'size_mb': filepath_obj.stat().st_size / (1024 * 1024),
                        # Inclure les m√©tadonn√©es compl√®tes
                        'metadata': meta.get('metadata', {}),
                        'final_win_rate': meta.get('final_win_rate', 0),
                        'final_draw_rate': meta.get('final_draw_rate', 0),
                        'final_loss_rate': meta.get('final_loss_rate', 0),
                        'total_episodes': meta.get('total_episodes', 0),
                    })
        else:
            # Fallback : charger directement depuis les fichiers
            for pkl_file in self.models_dir.glob("*.pkl"):
                try:
                    with open(pkl_file, 'rb') as f:
                        model_data = pickle.load(f)
                    
                    metadata = model_data.get('metadata', {})
                    models.append({
                        'name': pkl_file.name,
                        'path': str(pkl_file),
                        'timestamp': model_data.get('timestamp', 'N/A'),
                        'states': model_data['stats']['total_states'],
                        'epsilon': model_data['stats']['epsilon'],
                        'size_mb': pkl_file.stat().st_size / (1024 * 1024),
                        'metadata': metadata,
                        'final_win_rate': metadata.get('final_win_rate', 0),
                        'final_draw_rate': metadata.get('final_draw_rate', 0),
                        'final_loss_rate': metadata.get('final_loss_rate', 0),
                        'total_episodes': metadata.get('total_episodes', 0),
                    })
                except Exception as e:
                    print(f"Erreur lecture {pkl_file.name}: {e}")
        
        # Trier par date (plus r√©cent en premier)
        models.sort(key=lambda x: x['timestamp'], reverse=True)
        return models
    
    def delete_model(self, filepath: str) -> bool:
        """
        Supprime un mod√®le.
        
        Args:
            filepath: Chemin du fichier √† supprimer
        
        Returns:
            True si la suppression a r√©ussi
        """
        try:
            filepath = Path(filepath)
            if filepath.exists():
                filepath.unlink()
                # Retirer des m√©tadonn√©es
                if str(filepath) in self.metadata:
                    del self.metadata[str(filepath)]
                    self._save_metadata()
                print(f"‚úì Mod√®le supprim√©: {filepath}")
                return True
            else:
                print(f"‚úó Fichier introuvable: {filepath}")
                return False
        except Exception as e:
            print(f"‚úó Erreur lors de la suppression: {e}")
            return False
    
    def get_best_model(self, metric: str = 'composite_score') -> Optional[str]:
        """
        Retourne le chemin du meilleur mod√®le selon un crit√®re.
        
        Args:
            metric: Crit√®re de s√©lection ('composite_score', 'win_rate', 
                   'performance_score', 'states', 'epsilon', 'timestamp')
        
        Returns:
            Chemin du meilleur mod√®le ou None
        """
        # Utiliser le comparateur pour une analyse avanc√©e
        if metric in ['composite_score', 'win_rate', 'performance_score', 
                     'efficiency_score', 'robustness_score']:
            try:
                from .model_comparator import ModelComparator
                comparator = ModelComparator(str(self.models_dir))
                best_model = comparator.get_best_model(metric)
                return best_model['filepath'] if best_model else None
            except ImportError:
                print("‚ö† ModelComparator non disponible, utilisation m√©thode simple")
        
        # M√©thode simple pour les autres crit√®res
        models = self.list_models()
        if not models:
            return None
        
        if metric == 'states':
            best = max(models, key=lambda x: x['states'])
        elif metric == 'epsilon':
            best = min(models, key=lambda x: x['epsilon'])
        elif metric == 'timestamp':
            best = max(models, key=lambda x: x['timestamp'])
        else:
            best = models[0]
        
        return best['path']
    
    def _load_metadata(self) -> Dict:
        """Charge les m√©tadonn√©es des mod√®les"""
        if self.metadata_file.exists():
            try:
                with open(self.metadata_file, 'r') as f:
                    return json.load(f)
            except Exception:
                return {}
        return {}
    
    def _save_metadata(self):
        """Sauvegarde les m√©tadonn√©es"""
        try:
            with open(self.metadata_file, 'w') as f:
                json.dump(self.metadata, f, indent=2)
        except Exception as e:
            print(f"Erreur sauvegarde m√©tadonn√©es: {e}")
    
    def _update_metadata(self, filepath: str, model_data: Dict):
        """Met √† jour les m√©tadonn√©es avec les infos d'un mod√®le"""
        # Inclure TOUTES les m√©tadonn√©es du mod√®le
        full_metadata = model_data.get('metadata', {})
        
        self.metadata[filepath] = {
            'timestamp': model_data['timestamp'],
            'states': model_data['stats']['total_states'],
            'epsilon': model_data['stats']['epsilon'],
            'metadata': full_metadata,
            # Ajouter les infos importantes au niveau racine pour faciliter l'acc√®s
            'final_win_rate': full_metadata.get('final_win_rate', 0),
            'final_draw_rate': full_metadata.get('final_draw_rate', 0),
            'final_loss_rate': full_metadata.get('final_loss_rate', 0),
            'total_episodes': full_metadata.get('total_episodes', 0),
        }
        self._save_metadata()
    
    def export_to_json(self, agent, filepath: str):
        """
        Exporte la Q-table en format JSON (lisible).
        
        Args:
            agent: Agent √† exporter
            filepath: Chemin du fichier JSON
        """
        data = {
            'q_table': {
                str(state): {str(action): float(q) 
                           for action, q in actions.items()}
                for state, actions in agent.q_table.items()
            },
            'hyperparameters': {
                'alpha': agent.alpha,
                'gamma': agent.gamma,
                'epsilon': agent.epsilon
            },
            'stats': agent.get_stats(),
            'timestamp': datetime.now().isoformat()
        }
        
        with open(filepath, 'w') as f:
            json.dump(data, f, indent=2)
        
        print(f"‚úì Q-table export√©e en JSON: {filepath}")
    
    def load_best_model(self, agent, metric: str = 'composite_score') -> bool:
        """
        Charge automatiquement le meilleur mod√®le selon un crit√®re.
        
        Args:
            agent: Agent dans lequel charger le mod√®le
            metric: Crit√®re de s√©lection du meilleur mod√®le
        
        Returns:
            True si le chargement a r√©ussi, False sinon
        """
        best_path = self.get_best_model(metric)
        
        if best_path is None:
            print(f"‚úó Aucun mod√®le trouv√© pour le crit√®re '{metric}'")
            return False
        
        print(f"üìä Meilleur mod√®le selon '{metric}': {Path(best_path).name}")
        return self.load_model(agent, best_path)
    
    def analyze_models(self, top_n: int = 10) -> None:
        """
        Affiche une analyse comparative des mod√®les.
        
        Args:
            top_n: Nombre de mod√®les √† afficher dans le top
        """
        try:
            from .model_comparator import ModelComparator
            
            comparator = ModelComparator(str(self.models_dir))
            
            # Afficher le rapport
            report = comparator.generate_report()
            print(report)
            
            # Afficher le tableau des top mod√®les
            print("\nüìä TABLEAU D√âTAILL√â DES MEILLEURS MOD√àLES")
            print("=" * 80)
            df = comparator.compare_top_models(top_n)
            print(df.to_string(index=False))
            
        except ImportError as e:
            print(f"‚ö† Erreur d'import: {e}")
            print("Veuillez vous assurer que pandas est install√©: pip install pandas")
        except Exception as e:
            print(f"‚úó Erreur lors de l'analyse: {e}")
    
    def export_metrics(self, output_csv: str = "models/models_metrics.csv") -> None:
        """
        Exporte les m√©triques de tous les mod√®les en CSV.
        
        Args:
            output_csv: Chemin du fichier CSV de sortie
        """
        try:
            from .model_comparator import ModelComparator
            
            comparator = ModelComparator(str(self.models_dir))
            comparator.export_metrics_csv(output_csv)
            
        except ImportError as e:
            print(f"‚ö† Erreur d'import: {e}")
            print("Veuillez vous assurer que pandas est install√©: pip install pandas")
        except Exception as e:
            print(f"‚úó Erreur lors de l'export: {e}")